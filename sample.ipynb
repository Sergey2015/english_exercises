{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9cfa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import pyinflect\n",
    "\n",
    "import gensim.downloader as api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1096f998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# малая модель spacy\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# model glove wiki\n",
    "# внимание - очень долго скачивает, если она еще не установлена еще\n",
    "model = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2799108d-38c3-4a80-981a-b3d543f22cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw</th>\n",
       "      <th>type</th>\n",
       "      <th>transformed</th>\n",
       "      <th>options</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All the necessary ingredients for a pizza arri...</td>\n",
       "      <td>select_word</td>\n",
       "      <td>All the necessary _____ for a pizza arrived in...</td>\n",
       "      <td>[fabrics, dogs, ingredients]</td>\n",
       "      <td>ingredients</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All the necessary ingredients for a pizza arri...</td>\n",
       "      <td>write_word</td>\n",
       "      <td>All the necessary _____ for a pizza arrived in...</td>\n",
       "      <td>None</td>\n",
       "      <td>ingredients</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All the necessary ingredients for a pizza arri...</td>\n",
       "      <td>select_sentence</td>\n",
       "      <td>All the necessary _____ for a pizza arrived in...</td>\n",
       "      <td>[fabrics, dogs, ingredients]</td>\n",
       "      <td>ingredients</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All the necessary ingredients for a pizza arri...</td>\n",
       "      <td>select_pos</td>\n",
       "      <td>All the necessary ingredients for a pizza arri...</td>\n",
       "      <td>[nsubj, pobj]</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 raw             type   \n",
       "0  All the necessary ingredients for a pizza arri...      select_word  \\\n",
       "1  All the necessary ingredients for a pizza arri...       write_word   \n",
       "2  All the necessary ingredients for a pizza arri...  select_sentence   \n",
       "3  All the necessary ingredients for a pizza arri...       select_pos   \n",
       "\n",
       "                                         transformed   \n",
       "0  All the necessary _____ for a pizza arrived in...  \\\n",
       "1  All the necessary _____ for a pizza arrived in...   \n",
       "2  All the necessary _____ for a pizza arrived in...   \n",
       "3  All the necessary ingredients for a pizza arri...   \n",
       "\n",
       "                        options       answer  \n",
       "0  [fabrics, dogs, ingredients]  ingredients  \n",
       "1                          None  ingredients  \n",
       "2  [fabrics, dogs, ingredients]  ingredients  \n",
       "3                 [nsubj, pobj]        nsubj  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пример датасета – как упаковать упражнения\n",
    "\n",
    "df = pd.DataFrame(columns=['raw', 'type', 'transformed', 'options', 'answer'])\n",
    "\n",
    "df.loc[len(df)] = {'raw' : 'All the necessary ingredients for a pizza arrived in the next delivery.',\n",
    "                   'transformed' : 'All the necessary _____ for a pizza arrived in the next delivery.',\n",
    "                   'type' : 'select_word',\n",
    "                   'options' : ['fabrics', 'dogs', 'ingredients'],\n",
    "                   'answer' : 'ingredients'\n",
    "                  }\n",
    "\n",
    "df.loc[len(df)] = {'raw' : 'All the necessary ingredients for a pizza arrived in the next delivery.',\n",
    "                   'transformed' : 'All the necessary _____ for a pizza arrived in the next delivery.',\n",
    "                   'type' : 'write_word',\n",
    "                   'options' : None,\n",
    "                   'answer' : 'ingredients'\n",
    "                  }\n",
    "\n",
    "df.loc[len(df)] = {'raw' : 'All the necessary ingredients for a pizza arrived in the next delivery.',\n",
    "                   'transformed' : 'All the necessary _____ for a pizza arrived in the next delivery.',\n",
    "                   'type' : 'select_sentence',\n",
    "                   'options' : ['fabrics', 'dogs', 'ingredients'],\n",
    "                   'answer' : 'ingredients'\n",
    "                  }\n",
    "\n",
    "df.loc[len(df)] = {'raw' : 'All the necessary ingredients for a pizza arrived in the next delivery.',\n",
    "                   'transformed' : 'All the necessary ingredients for a pizza arrived in the next delivery.',\n",
    "                   'type' : 'select_pos',\n",
    "                   'options' : ['nsubj', 'pobj'],\n",
    "                   'answer' : 'nsubj'\n",
    "                  }\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc20615c-1d23-4aee-9ed3-6efae89eedbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4 entries, 0 to 3\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      4 non-null      object\n",
      " 1   exercise  4 non-null      object\n",
      " 2   type      4 non-null      object\n",
      " 3   options   3 non-null      object\n",
      " 4   answer    4 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 192.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b654d7d",
   "metadata": {},
   "source": [
    "# Similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "907448ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('planetary', 0.6683834195137024),\n",
       " ('gravity', 0.6506437659263611),\n",
       " ('galactic', 0.6414125561714172),\n",
       " ('primordial', 0.6334367990493774),\n",
       " ('gravitational', 0.6305052042007446),\n",
       " ('phenomena', 0.6299728751182556),\n",
       " ('earth', 0.6076391339302063),\n",
       " ('sonic', 0.6034857630729675),\n",
       " ('quantum', 0.5904744267463684),\n",
       " ('particle', 0.5867664217948914)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.similar_by_word('cosmic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8a55c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slow', 0.7502553462982178),\n",
       " ('slower', 0.6295009851455688),\n",
       " ('faster', 0.6158817410469055),\n",
       " ('too', 0.5972148180007935),\n",
       " ('turning', 0.5882929563522339),\n",
       " ('off', 0.5874745845794678),\n",
       " ('dangerous', 0.5860161185264587),\n",
       " ('worse', 0.5812638998031616),\n",
       " ('trouble', 0.5808587074279785),\n",
       " ('heavy', 0.5680885910987854)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['fast','bad'], negative=['good'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e0a51fc-6239-46ad-82d5-3b828ec01337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('slow', 0.7045032978057861),\n",
       " ('too', 0.6350111961364746),\n",
       " ('faster', 0.6330539584159851),\n",
       " ('turning', 0.6328635811805725),\n",
       " ('turn', 0.6146118640899658),\n",
       " ('rather', 0.6059424877166748),\n",
       " ('moving', 0.6030642986297607),\n",
       " ('low', 0.602108895778656),\n",
       " ('slower', 0.599425196647644),\n",
       " ('big', 0.5981428027153015)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['fast','negative'], negative=['positive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd447cc",
   "metadata": {},
   "source": [
    "# Sentence transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9a1c987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the necessary ingredients for a pizza arrived in the next delivery.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All the needed spices for a burger arrive in the week supply .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sent = []\n",
    "i=5\n",
    "for token in nlp(\"All the necessary ingredients for a pizza arrived in the next delivery.\"):\n",
    "    if token.pos_ in ['NOUN', 'VERB', 'ADV', 'ADJ']:\n",
    "        try:\n",
    "            new_sent += [model.most_similar(token.text,topn=i)[np.random.randint(0,i)][0]]\n",
    "        except:\n",
    "            new_sent += [token.text]\n",
    "    else:\n",
    "        new_sent += [token.text]\n",
    "        \n",
    "print('All the necessary ingredients for a pizza arrived in the next delivery.')\n",
    "' '.join(new_sent)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a19f6e",
   "metadata": {},
   "source": [
    "# Inflecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "552a3a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best\n",
      "easiest\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(\"I think it's a good idea and easy to use\"):\n",
    "    if token.pos_=='ADJ':\n",
    "        print(token._.inflect('JJS'))          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeadfea",
   "metadata": {},
   "source": [
    "# Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0d81e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t–\t Case=Nom|Number=Sing|Person=1|PronType=Prs\n",
      "think \t–\t Tense=Pres|VerbForm=Fin\n",
      "it \t–\t Case=Nom|Gender=Neut|Number=Sing|Person=3|PronType=Prs\n",
      "'s \t–\t Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin\n",
      "a \t–\t Definite=Ind|PronType=Art\n",
      "good \t–\t Degree=Pos\n",
      "idea \t–\t Number=Sing\n",
      "and \t–\t ConjType=Cmp\n",
      "easy \t–\t Degree=Pos\n",
      "to \t–\t \n",
      "use \t–\t VerbForm=Inf\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(\"I think it's a good idea and easy to use\"):\n",
    "    print(token.text, '\\t–\\t', token.morph) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09bd246",
   "metadata": {},
   "source": [
    "# Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75497656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the necessary ingredients : ingredients : nsubj : arrived\n",
      "a pizza : pizza : pobj : for\n",
      "the next delivery : delivery : pobj : in\n"
     ]
    }
   ],
   "source": [
    "for chunk in nlp(\"All the necessary ingredients for a pizza arrived in the next delivery\").noun_chunks:\n",
    "    print(chunk.text, ':', \n",
    "          chunk.root.text, ':', \n",
    "          chunk.root.dep_, ':', \n",
    "          chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6af68934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All : predet\n",
      "the : det\n",
      "necessary : amod\n",
      "ingredients : nsubj\n",
      "for : prep\n",
      "a : det\n",
      "pizza : pobj\n",
      "arrived : ROOT\n",
      "in : prep\n",
      "the : det\n",
      "next : amod\n",
      "delivery : pobj\n"
     ]
    }
   ],
   "source": [
    "for token in nlp(\"All the necessary ingredients for a pizza arrived in the next delivery\"):\n",
    "    print(token.text, ':', token.dep_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903550c3-0b40-4eb3-811f-b6bfe7b2c6f3",
   "metadata": {},
   "source": [
    "# Gensim models and vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acb4cf82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info = api.info()\n",
    "# print(json.dumps(info, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cb2b0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20-newsgroups (18846 records): The notorious collection of approximatel...\n",
      "__testing_matrix-synopsis (-1 records): [THIS IS ONLY FOR TESTING] Synopsis of t...\n",
      "__testing_multipart-matrix-synopsis (-1 records): [THIS IS ONLY FOR TESTING] Synopsis of t...\n",
      "fake-news (12999 records): News dataset, contains text and metadata...\n",
      "patent-2017 (353197 records): Patent Grant Full Text. Contains the ful...\n",
      "quora-duplicate-questions (404290 records): Over 400,000 lines of potential question...\n",
      "semeval-2016-2017-task3-subtaskA-unannotated (189941 records): SemEval 2016 / 2017 Task 3 Subtask A una...\n",
      "semeval-2016-2017-task3-subtaskBC (-1 records): SemEval 2016 / 2017 Task 3 Subtask B and...\n",
      "text8 (1701 records): First 100,000,000 bytes of plain text fr...\n",
      "wiki-english-20171001 (4924894 records): Extracted Wikipedia dump from October 20...\n"
     ]
    }
   ],
   "source": [
    "for corpus_name, corpus_data in sorted(info['corpora'].items()):\n",
    "    print(\n",
    "        '%s (%d records): %s' % (\n",
    "            corpus_name,\n",
    "            corpus_data.get('num_records', -1),\n",
    "            corpus_data['description'][:40] + '...',\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2329c168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__testing_word2vec-matrix-synopsis (-1 records): [THIS IS ONLY FOR TESTING] Word vecrors ...\n",
      "conceptnet-numberbatch-17-06-300 (1917247 records): ConceptNet Numberbatch consists of state...\n",
      "fasttext-wiki-news-subwords-300 (999999 records): 1 million word vectors trained on Wikipe...\n",
      "glove-twitter-100 (1193514 records): Pre-trained vectors based on  2B tweets,...\n",
      "glove-twitter-200 (1193514 records): Pre-trained vectors based on 2B tweets, ...\n",
      "glove-twitter-25 (1193514 records): Pre-trained vectors based on 2B tweets, ...\n",
      "glove-twitter-50 (1193514 records): Pre-trained vectors based on 2B tweets, ...\n",
      "glove-wiki-gigaword-100 (400000 records): Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-200 (400000 records): Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-300 (400000 records): Pre-trained vectors based on Wikipedia 2...\n",
      "glove-wiki-gigaword-50 (400000 records): Pre-trained vectors based on Wikipedia 2...\n",
      "word2vec-google-news-300 (3000000 records): Pre-trained vectors trained on a part of...\n",
      "word2vec-ruscorpora-300 (184973 records): Word2vec Continuous Skipgram vectors tra...\n"
     ]
    }
   ],
   "source": [
    "for model_name, model_data in sorted(info['models'].items()):\n",
    "    print(\n",
    "        '%s (%d records): %s' % (\n",
    "            model_name,\n",
    "            model_data.get('num_records', -1),\n",
    "            model_data['description'][:40] + '...',\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b2605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
